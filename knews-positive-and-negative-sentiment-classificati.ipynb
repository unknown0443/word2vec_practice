{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install transformers\n#!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:24.136992Z","iopub.execute_input":"2025-01-23T04:53:24.137331Z","iopub.status.idle":"2025-01-23T04:53:32.509185Z","shell.execute_reply.started":"2025-01-23T04:53:24.137299Z","shell.execute_reply":"2025-01-23T04:53:32.507841Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n^C\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 데이터 로드를 위함\nfrom datasets import load_dataset\n\n# 기본 파이썬 패키지\nimport pandas as pd\nimport numpy as np\nimport datetime\nfrom tqdm import tqdm\n\n# GPT 사용을 위함\nimport torch\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom datasets import Dataset\n# for padding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# 전처리 및 평가 지표\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:58:32.044424Z","iopub.execute_input":"2025-01-23T04:58:32.044866Z","iopub.status.idle":"2025-01-23T04:58:32.051132Z","shell.execute_reply.started":"2025-01-23T04:58:32.044835Z","shell.execute_reply":"2025-01-23T04:58:32.050034Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:58:33.412686Z","iopub.execute_input":"2025-01-23T04:58:33.413013Z","iopub.status.idle":"2025-01-23T04:58:34.359933Z","shell.execute_reply.started":"2025-01-23T04:58:33.412987Z","shell.execute_reply":"2025-01-23T04:58:34.358769Z"}},"outputs":[{"name":"stdout","text":"--2025-01-23 04:58:33--  https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1319001 (1.3M) [text/plain]\nSaving to: ‘finance_data.csv.3’\n\nfinance_data.csv.3  100%[===================>]   1.26M  4.85MB/s    in 0.3s    \n\n2025-01-23 04:58:34 (4.85 MB/s) - ‘finance_data.csv.3’ saved [1319001/1319001]\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"df = pd.read_csv('finance_data.csv')\nprint('샘플의 개수 :', len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:22.846307Z","iopub.execute_input":"2025-01-23T04:59:22.846701Z","iopub.status.idle":"2025-01-23T04:59:22.880702Z","shell.execute_reply.started":"2025-01-23T04:59:22.846667Z","shell.execute_reply":"2025-01-23T04:59:22.879637Z"}},"outputs":[{"name":"stdout","text":"샘플의 개수 : 4846\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"df['labels'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:23.437371Z","iopub.execute_input":"2025-01-23T04:59:23.437964Z","iopub.status.idle":"2025-01-23T04:59:23.445905Z","shell.execute_reply.started":"2025-01-23T04:59:23.437924Z","shell.execute_reply":"2025-01-23T04:59:23.444777Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"labels\n0    2879\n1    1363\n2     604\nName: count, dtype: int64"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:24.051314Z","iopub.execute_input":"2025-01-23T04:59:24.051724Z","iopub.status.idle":"2025-01-23T04:59:24.061995Z","shell.execute_reply.started":"2025-01-23T04:59:24.051693Z","shell.execute_reply":"2025-01-23T04:59:24.060905Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"   labels                                           sentence  \\\n0       0  According to Gran, the company has no plans to...   \n1       0  Technopolis plans to develop in stages an area...   \n2       2  The international electronic industry company ...   \n3       1  With the new production plant the company woul...   \n4       1  According to the company's updated strategy fo...   \n\n                                        kor_sentence  \n0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>sentence</th>\n      <th>kor_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>According to Gran, the company has no plans to...</td>\n      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>The international electronic industry company ...</td>\n      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>With the new production plant the company woul...</td>\n      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>According to the company's updated strategy fo...</td>\n      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"df.to_csv('finance_data.csv', index=False, encoding='utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:26.602271Z","iopub.execute_input":"2025-01-23T04:59:26.602827Z","iopub.status.idle":"2025-01-23T04:59:26.643397Z","shell.execute_reply.started":"2025-01-23T04:59:26.602768Z","shell.execute_reply":"2025-01-23T04:59:26.642613Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"all_data = load_dataset(\n        \"csv\",\n        data_files={\n            \"train\": \"finance_data.csv\",\n        },\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:26.980283Z","iopub.execute_input":"2025-01-23T04:59:26.980684Z","iopub.status.idle":"2025-01-23T04:59:27.667672Z","shell.execute_reply.started":"2025-01-23T04:59:26.980650Z","shell.execute_reply":"2025-01-23T04:59:27.666738Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c19b02449fd4405b19faf362bc52061"}},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"cs = all_data['train'].train_test_split(0.2, seed=777)\ntrain_cs = cs[\"train\"]\ntest_cs = cs[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:27.668872Z","iopub.execute_input":"2025-01-23T04:59:27.669216Z","iopub.status.idle":"2025-01-23T04:59:27.684180Z","shell.execute_reply.started":"2025-01-23T04:59:27.669188Z","shell.execute_reply":"2025-01-23T04:59:27.682963Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# 훈련 데이터를 다시 8:2로 분리 후 훈련 데이터와 검증 데이터로 저장\ncs = train_cs.train_test_split(0.2, seed=777)\ntrain_cs = cs[\"train\"]\nvalid_cs = cs[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:00:03.000591Z","iopub.execute_input":"2025-01-23T05:00:03.001104Z","iopub.status.idle":"2025-01-23T05:00:03.020415Z","shell.execute_reply.started":"2025-01-23T05:00:03.001060Z","shell.execute_reply":"2025-01-23T05:00:03.019342Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"ataset({\n    features: ['labels', 'sentence', 'kor_sentence'],\n    num_rows: 3100\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:00:38.030979Z","iopub.execute_input":"2025-01-23T05:00:38.031363Z","iopub.status.idle":"2025-01-23T05:00:38.061602Z","shell.execute_reply.started":"2025-01-23T05:00:38.031327Z","shell.execute_reply":"2025-01-23T05:00:38.060264Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-798bbc11f987>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ataset({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kor_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n","\u001b[0;31mNameError\u001b[0m: name 'ataset' is not defined"],"ename":"NameError","evalue":"name 'ataset' is not defined","output_type":"error"}],"execution_count":64},{"cell_type":"code","source":"Dataset({\n    features: ['labels', 'sentence', 'kor_sentence'],\n    num_rows: 776\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:00:51.998773Z","iopub.execute_input":"2025-01-23T05:00:51.999135Z","iopub.status.idle":"2025-01-23T05:00:52.027923Z","shell.execute_reply.started":"2025-01-23T05:00:51.999105Z","shell.execute_reply":"2025-01-23T05:00:52.026696Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-146ab5a5c5bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Dataset({\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kor_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m776\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n","\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"],"ename":"NameError","evalue":"name 'features' is not defined","output_type":"error"}],"execution_count":65},{"cell_type":"code","source":"Dataset({\n    features: ['labels', 'sentence', 'kor_sentence'],\n    num_rows: 970\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:00:06.262733Z","iopub.execute_input":"2025-01-23T05:00:06.263060Z","iopub.status.idle":"2025-01-23T05:00:06.293396Z","shell.execute_reply.started":"2025-01-23T05:00:06.263036Z","shell.execute_reply":"2025-01-23T05:00:06.292042Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-0493154852da>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Dataset({\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kor_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m970\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n","\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"],"ename":"NameError","evalue":"name 'features' is not defined","output_type":"error"}],"execution_count":63},{"cell_type":"code","source":"print('두번째 샘플 출력 :', train_cs['kor_sentence'][1])\nprint('두번째 샘플의 레이블 출력 :', train_cs['labels'][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:58:37.628388Z","iopub.status.idle":"2025-01-23T04:58:37.628810Z","shell.execute_reply":"2025-01-23T04:58:37.628668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_sentences[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:00.060916Z","iopub.execute_input":"2025-01-23T04:59:00.061299Z","iopub.status.idle":"2025-01-23T04:59:00.092630Z","shell.execute_reply.started":"2025-01-23T04:59:00.061265Z","shell.execute_reply":"2025-01-23T04:59:00.091067Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-5991e3195859>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test_sentences' is not defined"],"ename":"NameError","evalue":"name 'test_sentences' is not defined","output_type":"error"}],"execution_count":48},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\n# 한국어 GPT 중 하나인 'skt/kogpt2-base-v2'를 사용.\ntokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:00.644260Z","iopub.execute_input":"2025-01-23T04:59:00.644616Z","iopub.status.idle":"2025-01-23T04:59:00.674216Z","shell.execute_reply.started":"2025-01-23T04:59:00.644587Z","shell.execute_reply":"2025-01-23T04:59:00.672527Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-68e435913fc1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 한국어 GPT 중 하나인 'skt/kogpt2-base-v2'를 사용.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skt/kogpt2-base-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"],"ename":"NameError","evalue":"name 'AutoTokenizer' is not defined","output_type":"error"}],"execution_count":49},{"cell_type":"code","source":"# 최대 길이는 128\nmax_len = 128\n\ndef data_to_tensor (sentences, labels, max_len):\n  # 정수 인코딩 과정. 각 텍스트를 토큰화한 후에 Vocabulary에 맵핑되는 정수 시퀀스로 변환한다.\n  # ex) ['안녕하세요'] ==> ['안', '녕', '하세요'] ==> [231, 52, 45]\n  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n\n  # pad_sequences는 패딩을 위한 모듈. 주어진 최대 길이를 위해서 뒤에서 패딩 토큰의 번호로 채워준다.\n  # ex) [231, 52, 45] ==> [231, 52, 45, 패딩 토큰, 패딩 토큰, 패딩 토큰]\n  pad_token = tokenizer.encode('<pad>')[0]\n  input_ids = pad_sequences(input_ids, maxlen=max_len, value=pad_token, dtype=\"long\", truncating=\"post\", padding=\"post\") \n\n  attention_masks = []\n\n  for seq in input_ids:\n      seq_mask = [float(i != pad_token) for i in seq]\n      attention_masks.append(seq_mask)\n\n  tensor_inputs = torch.tensor(input_ids)\n  tensor_labels = torch.tensor(labels)\n  tensor_masks = torch.tensor(attention_masks)\n\n  return tensor_inputs, tensor_labels, tensor_masks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:03.922349Z","iopub.execute_input":"2025-01-23T04:59:03.922748Z","iopub.status.idle":"2025-01-23T04:59:03.929559Z","shell.execute_reply.started":"2025-01-23T04:59:03.922716Z","shell.execute_reply":"2025-01-23T04:59:03.928321Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# 학습 데이터, 검증 데이터, 테스트 데이터에 대해서\n# 정수 인코딩 결과, 레이블, 어텐션 마스크를 각각 inputs, labels, masks에 저장.\ntrain_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels, max_len)\nvalidation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels, max_len)\ntest_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels, max_len)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:07.171417Z","iopub.execute_input":"2025-01-23T04:59:07.171823Z","iopub.status.idle":"2025-01-23T04:59:07.201292Z","shell.execute_reply.started":"2025-01-23T04:59:07.171794Z","shell.execute_reply":"2025-01-23T04:59:07.199509Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-ac2ba9b5d6c5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 데이터, 검증 데이터, 테스트 데이터에 대해서\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 정수 인코딩 결과, 레이블, 어텐션 마스크를 각각 inputs, labels, masks에 저장.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_sentences' is not defined"],"ename":"NameError","evalue":"name 'train_sentences' is not defined","output_type":"error"}],"execution_count":51},{"cell_type":"code","source":"정수 인코딩 결과: tensor([ 9250,  9258, 17970,  9436, 37825,  9220,  7239,  7756, 11276, 20835,\n         9133, 10644,  9427,  9706, 13872,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3])\n--------------------\n원본 문장 복원 결과: 그러나 그는 운전자가 2중 추돌사고를 당한 후 그를 다시 발견했다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n--------------------\n어텐션 마스크: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.])\n--------------------\n샘플의 길이: 128\n--------------------\n레이블: tensor(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:08.186982Z","iopub.execute_input":"2025-01-23T04:59:08.187307Z","iopub.status.idle":"2025-01-23T04:59:08.201412Z","shell.execute_reply.started":"2025-01-23T04:59:08.187283Z","shell.execute_reply":"2025-01-23T04:59:08.199979Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-e18863b26880>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    원본 문장 복원 결과: 그러나 그는 운전자가 2중 추돌사고를 당한 후 그를 다시 발견했다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"],"ename":"SyntaxError","evalue":"invalid decimal literal (<ipython-input-52-e18863b26880>, line 15)","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"batch_size = 32\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:11.368121Z","iopub.execute_input":"2025-01-23T04:59:11.368535Z","iopub.status.idle":"2025-01-23T04:59:11.397256Z","shell.execute_reply.started":"2025-01-23T04:59:11.368500Z","shell.execute_reply":"2025-01-23T04:59:11.395674Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-bebf3c8de48f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_inputs' is not defined"],"ename":"NameError","evalue":"name 'train_inputs' is not defined","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.104086Z","iopub.status.idle":"2025-01-23T04:53:34.104469Z","shell.execute_reply":"2025-01-23T04:53:34.104318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = TensorDataset(test_inputs, test_masks, test_labels)\ntest_sampler = RandomSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.105576Z","iopub.status.idle":"2025-01-23T04:53:34.105959Z","shell.execute_reply":"2025-01-23T04:53:34.105831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print('No GPU available, using the CPU instead.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.108027Z","iopub.status.idle":"2025-01-23T04:53:34.108412Z","shell.execute_reply":"2025-01-23T04:53:34.108243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla T4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.110224Z","iopub.status.idle":"2025-01-23T04:53:34.110648Z","shell.execute_reply":"2025-01-23T04:53:34.110488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_labels = 3\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"skt/kogpt2-base-v2\", num_labels=num_labels)\nmodel.cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.111659Z","iopub.status.idle":"2025-01-23T04:53:34.112069Z","shell.execute_reply":"2025-01-23T04:53:34.111925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 몇 번의 에포크(전체 데이터에 대한 학습 횟수)를 할 것인지 선택\nepochs = 3\n\n# 옵티마이저 선택\noptimizer = AdamW(model.parameters(), lr = 2e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.113086Z","iopub.status.idle":"2025-01-23T04:53:34.113610Z","shell.execute_reply":"2025-01-23T04:53:34.113357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def metrics(predictions, labels):\n    # predictions: 모델이 예측한 결과값들의 리스트 또는 배열\n    # labels: 실제 정답 레이블들의 리스트 또는 배열\n\n    # 예측값과 실제 레이블을 별도의 변수에 할당\n    y_pred = predictions\n    y_true = labels\n\n    # 사용 가능한 메트릭들을 계산\n\n    # 정확도 (Accuracy)\n    # 전체 예측 중에서 올바르게 예측한 비율\n    accuracy = accuracy_score(y_true, y_pred)\n\n    # 매크로 평균 F1 점수 (Macro-averaged F1 Score)\n    # 클래스별로 F1 점수를 계산한 후, 그 평균을 구함\n    # zero_division=0 옵션은 분모가 0일 경우 0을 반환하도록 설정\n    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n\n    # 마이크로 평균 F1 점수 (Micro-averaged F1 Score)\n    # 전체 데이터에 대해 단일 F1 점수를 계산\n    # 클래스 불균형이 심한 경우에 적합\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n\n    # 가중 평균 F1 점수 (Weighted-averaged F1 Score)\n    # 각 클래스의 F1 점수에 해당 클래스의 샘플 수를 가중치로 곱한 후 평균을 구함\n    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n\n    # 계산된 메트릭 결과를 딕셔너리 형태로 리턴\n    metrics = {'accuracy': accuracy,\n               'f1_macro': f1_macro_average,\n               'f1_micro': f1_micro_average,\n               'f1_weighted': f1_weighted_average}\n    return metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.114554Z","iopub.status.idle":"2025-01-23T04:53:34.114965Z","shell.execute_reply":"2025-01-23T04:53:34.114753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(model, train_dataloader, optimizer, device):\n    \"\"\"\n    하나의 에포크 동안 모델을 학습시키는 함수입니다.\n\n    Parameters:\n    model (torch.nn.Module): 학습시킬 모델 객체.\n    train_dataloader (torch.utils.data.DataLoader): 학습 데이터셋의 DataLoader.\n    optimizer (torch.optim.Optimizer): 최적화 알고리즘을 구현하는 객체.\n    device (torch.device): 학습에 사용할 장치(CPU 또는 CUDA).\n\n    Returns:\n    float: 평균 학습 손실값.\n    \"\"\"\n\n    total_train_loss = 0  # 학습 손실을 누적할 변수 초기화\n    model.train()  # 모델을 학습 모드로 설정\n\n    # 학습 데이터로더를 순회하며 배치 단위로 학습\n    for step, batch in tqdm(enumerate(train_dataloader), desc=\"Training Batch\"):\n        batch = tuple(t.to(device) for t in batch)  # DataLoader에서 배치를 받아 각 텐서를 지정된 장치로 이동\n        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n\n        # 모델에 배치를 전달하여 손실값 계산\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n        # 손실값 추출\n        loss = outputs.loss\n\n        optimizer.zero_grad()  # 기울기(gradient) 초기화\n        loss.backward()  # 역전파를 통해 기울기(gradient) 계산\n        optimizer.step()  # 매개변수 업데이트\n\n        total_train_loss += loss.item()  # 총 손실에 더함\n\n    avg_train_loss = total_train_loss / len(train_dataloader)  # 평균 학습 손실 계산\n\n    return avg_train_loss  # 평균 학습 손실 반환\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.116124Z","iopub.status.idle":"2025-01-23T04:53:34.116601Z","shell.execute_reply":"2025-01-23T04:53:34.116376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, validation_dataloader, device):\n    \"\"\"\n    모델을 사용하여 검증 데이터셋에 대한 평가를 수행하는 함수입니다.\n\n    Parameters:\n    model (torch.nn.Module): 평가할 모델 객체.\n    validation_dataloader (torch.utils.data.DataLoader): 검증 데이터셋의 DataLoader.\n    device (torch.device): 평가에 사용할 장치(CPU 또는 CUDA).\n\n    Returns:\n    float: 평균 검증 손실값.\n    dict: 다양한 평가 지표(metrics)에 대한 값들을 담은 사전.\n    \"\"\"\n\n    model.eval()  # 모델을 평가 모드로 설정\n\n    total_eval_loss = 0  # 검증 손실을 누적할 변수 초기화\n    predictions, true_labels = [], []  # 예측값과 실제 라벨값을 저장할 리스트 초기화\n\n    # 검증 데이터로더를 순회하며 배치 단위로 평가\n    for batch in validation_dataloader:\n        batch = tuple(t.to(device) for t in batch)  # 배치 데이터를 디바이스로 이동\n        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n\n        with torch.no_grad():  # 기울기(gradient) 계산을 수행하지 않음\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n        # 모델 출력에서 손실값 추출\n        if outputs.loss is not None:\n            loss = outputs.loss\n            total_eval_loss += loss.item()  # 총 손실에 더함\n\n        logits = outputs.logits.detach().cpu().numpy()  # 모델 예측값(로짓)을 numpy 배열로 변환\n        label_ids = b_labels.to('cpu').numpy()  # 실제 라벨값을 numpy 배열로 변환\n\n        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정 (예시: logits = [3.513, -0.309, -2.111] ==> 예측: 0)\n        predictions.extend(np.argmax(logits, axis=1).flatten()) # 예측된 클래스를 리스트에 추가\n        true_labels.extend(label_ids.flatten()) # 실제 레이블 값을 리스트에 추가\n\n    eval_metrics = metrics(predictions, true_labels)\n\n    return total_eval_loss / len(validation_dataloader), eval_metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.117835Z","iopub.status.idle":"2025-01-23T04:53:34.118292Z","shell.execute_reply":"2025-01-23T04:53:34.118099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 최소 검증 손실 초기화\nmin_val_loss = float('inf')\n\n# 메인 학습 & 평가 루프\nfor epoch_i in range(0, epochs):\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n\n    # 학습 단계\n    train_epoch(model, train_dataloader, optimizer, device)\n\n    print(\"\\nRunning Validation...\")\n    # 검증 단계\n    avg_val_loss, eval_metrics = evaluate(model, validation_dataloader, device)\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n    print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n    print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n    print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n\n    # 검증 손실이 현재까지의 최소값보다 작은 경우 체크포인트 저장\n    if avg_val_loss < min_val_loss:\n        print(f\"Validation loss decreased ({min_val_loss:.2f} --> {avg_val_loss:.2f}).  Saving model ...\")\n        # 베스트 모델 저장\n        torch.save(model.state_dict(), 'model_checkpoint.pt')\n        # 최소 검증 손실 업데이트\n        min_val_loss = avg_val_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.119590Z","iopub.status.idle":"2025-01-23T04:53:34.119970Z","shell.execute_reply":"2025-01-23T04:53:34.119830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"======== Epoch 1 / 3 ========\nTraining Batch: 97it [00:34,  2.81it/s]\n\nRunning Validation...\n  Validation Loss: 0.43\n  Accuracy: 0.84\n  F1 Macro: 0.82\n  F1 Micro: 0.84\n  F1 Weighted: 0.84\nValidation loss decreased (inf --> 0.43).  Saving model ...\n======== Epoch 2 / 3 ========\nTraining Batch: 97it [00:33,  2.86it/s]\n\nRunning Validation...\n  Validation Loss: 0.53\n  Accuracy: 0.79\n  F1 Macro: 0.78\n  F1 Micro: 0.79\n  F1 Weighted: 0.79\n======== Epoch 3 / 3 ========\nTraining Batch: 97it [00:34,  2.84it/s]\n\nRunning Validation...\n  Validation Loss: 0.55\n  Accuracy: 0.83\n  F1 Macro: 0.81\n  F1 Micro: 0.83\n  F1 Weighted: 0.83\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.120946Z","iopub.status.idle":"2025-01-23T04:53:34.121273Z","shell.execute_reply":"2025-01-23T04:53:34.121149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 베스트 모델 로드\nmodel.load_state_dict(torch.load(\"model_checkpoint.pt\"))\n\navg_val_loss, eval_metrics = evaluate(model, test_dataloader, device)\nprint(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\nprint(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\nprint(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\nprint(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\nprint(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.122359Z","iopub.status.idle":"2025-01-23T04:53:34.122818Z","shell.execute_reply":"2025-01-23T04:53:34.122627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"  Test Loss: 0.45\n  Accuracy: 0.82\n  F1 Macro: 0.79\n  F1 Micro: 0.82\n  F1 Weighted: 0.82\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.123654Z","iopub.status.idle":"2025-01-23T04:53:34.124107Z","shell.execute_reply":"2025-01-23T04:53:34.123913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, return_all_scores=True, function_to_apply='softmax')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.124943Z","iopub.status.idle":"2025-01-23T04:53:34.125394Z","shell.execute_reply":"2025-01-23T04:53:34.125198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = pipe('SK하이닉스가 매출이 급성장하였다')\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.126711Z","iopub.status.idle":"2025-01-23T04:53:34.127160Z","shell.execute_reply":"2025-01-23T04:53:34.126968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[[{'label': 'LABEL_0', 'score': 0.018421756103634834}, {'label': 'LABEL_1', 'score': 0.9810470938682556}, {'label': 'LABEL_2', 'score': 0.0005311687709763646}]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.128401Z","iopub.status.idle":"2025-01-23T04:53:34.128917Z","shell.execute_reply":"2025-01-23T04:53:34.128706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# return_all_scores 제거\npipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, function_to_apply='softmax')\n\nresult = pipe('SK하이닉스가 매출이 급성장하였다')\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.129718Z","iopub.status.idle":"2025-01-23T04:53:34.130189Z","shell.execute_reply":"2025-01-23T04:53:34.129989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[{'label': 'LABEL_1', 'score': 0.9810470938682556}]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.131215Z","iopub.status.idle":"2025-01-23T04:53:34.131678Z","shell.execute_reply":"2025-01-23T04:53:34.131483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}\n\ndef prediction(text):\n  result = pipe(text)\n\n  return [label_dict[result[0]['label']]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.132540Z","iopub.status.idle":"2025-01-23T04:53:34.132995Z","shell.execute_reply":"2025-01-23T04:53:34.132790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prediction('네이버가 매출이 급성장하였다')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.133842Z","iopub.status.idle":"2025-01-23T04:53:34.134306Z","shell.execute_reply":"2025-01-23T04:53:34.134103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prediction('ChatGPT의 등장으로 인공지능 스타트업들은 위기다')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.135386Z","iopub.status.idle":"2025-01-23T04:53:34.135852Z","shell.execute_reply":"2025-01-23T04:53:34.135660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prediction('인공지능 기술의 발전으로 누군가는 기회를 얻을 것이고, 누군가는 얻지 못할 것이다')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:53:34.136991Z","iopub.status.idle":"2025-01-23T04:53:34.137433Z","shell.execute_reply":"2025-01-23T04:53:34.137235Z"}},"outputs":[],"execution_count":null}]}